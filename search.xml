<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[记GitLab服务器宕机的迁移过程]]></title>
    <url>%2F2019%2F06%2F17%2Fgitlab-migrations%2F</url>
    <content type="text"><![CDATA[问题描述 公司gitlab服务器的硬件比较老旧，内存也相对较少，在一次增加内存条的时候，由于和主板不兼容的问题，导致系统引导出错，无法再进入系统并运行gitlab了，而公司所有项目都在该gitlab服务器上面，开发小组的工作受到了很大的影响，所以修复gitlab服务器变得刻不容缓。 解决问题 第一次：尝试修复系统 从u盘启动，并挂载之前gitlab服务器的系统盘，查找原因是系统引导出现问题，用网上找到的一些办法来尝试修复引导均失败了，多次尝试无果之后开始尝试其他方法，由于gitlab兼容性较强，所以想着可不可以在gitlab服务无法启动的情况下通过转移文件来迁移整个gitlab,在网上查了一些资料之后发现的确可行，话不多说，开始实践吧。 第二次：尝试转移gitlab 1. 查看gitlab的版本 默认安装在/opt/gitlab/, 找到version-manifest.txt文件，文件第一行记录gitlab的版本： 1gitlab-ce 11.0.3 2. 在新服务器上安装该版本的gitlab 安装之后，执行 1sudo gitlab-ctl reconfigure 将gitlab服务正常启动，然后将其服务关闭sudo gitlab-ctl stop，然后再进行下面的操作。 注意：版本一定保持一致，否则迁移将会失败。 3. 将旧服务器上的仓库拷贝到新服务器上 3.1 将旧服务器上位于相对位置的**/var/opt/gitlab/git-data/**目录下面的repositories目录打包，拷贝到新服务器上（如果旧服务的硬盘直接挂载在新服务器上，则可以直接拷贝）。 1234567# 本次演示，旧服务器挂了，需要通过U盘启动，因此旧服务器和新服务器直接传文件，只能通过网络。# 当前位于旧服务器的/var/opt/gitlab/git-data/目录下# gitlab使用默认配置时，仓库在repositories目录下面tar -zcvf repositories.tar.gz repositories/# 将包通过网络拷贝到新服务器的当前用户的家目录下面，保证有权限向新服务器写入数据scp repositories.tar.gz 新服务器用户@新服务器的IP地址:~/ 3.2 将数据解压，并修改权限，移动到新服务器的**/var/opt/gitlab/git-data/**下面。 12345678# 解压包tar -zxvf repositories.tar.gz# 修改属主属组sudo chown -R git.root repositories# 移动仓库sudo mv repositories /var/opt/gitlab/git-data/ 4. 将旧服务器上的存储在postgresql（默认安装配置的gitlab的数据，存储在postgresql中）中的数据拷贝到新服务器上。 4.1 将旧服务器上位于相对位置的/var/opt/gitlab/postgresql/目录下面的data目录打包，拷贝到新服务上。 12345# 打包tar -zcvf data.tar.gz data/# 发送到新服务器的用户的家目录中scp data.tar.gz 新服务器的用户@新服务器的IP地址:~/ 4.2 解压，并修改属主属组，移动到新服务器的/var/opt/gitlab/postgresql/目录下面。 1234567891011# 解压tar -xvf data.tar.gz# 修改属主属组sudo chown -R gitlab-psql.root data# 移动数据（移动数据较快，又可以保留文件的原始权限）sudo mv data /var/opt/gitlab/postgresql/# 或者使用带权限的拷贝sudo cp -rp data /var/opt/gitlab/postgresql/ 5.将旧服务器上的配置文件拷贝到新服务器上 12cd /etc/gitlabtar gitlab.rb 新服务器的用户@新服务器的IP地址:~/ 新服务器上: 12sudo mv /etc/gitlab/gitlab.rb /etc/gitlab/gitlab.rb.bck # 备份下配置文件sudo mv gitlab.rb /etc/gitlab # 使用旧服务器的配置文件 6.将旧服务器上的上传文件拷贝到新服务器上。 6.1 将旧服务器上位于相对位置的/var/opt/gitlab/gitlab-rails/目录下面的uploads目录打包，拷贝到新服务上。 12345# 打包tar -zcvf uploads.tar.gz uploads/# 发送到新服务器的用户的家目录中scp uploads.tar.gz 新服务器的用户@新服务器的IP地址:~/ 6.2 解压，并修改属主属组，移动到新服务器的/var/opt/gitlab/gitlab-rails/目录下面。 1234567891011# 解压tar -xvf uploads.tar.gz# 修改属主属组sudo chown -R git.root uploads# 移动数据（移动数据较快，又可以保留文件的原始权限）sudo mv uploads /var/opt/gitlab/gitlab-rails/# 或者使用带权限的拷贝sudo cp -rp uploads /var/opt/gitlab/gitlab-rails/ 7. 重新配置gitlab 1sudo gitlab-ctl reconfigure 8.启动服务 12345678# 启动服务sudo gitlab-ctl start# 查看启动状态sudo gitlab-ctl status# 查看实时启动状态sudo gitlab-ctl tail 参考 gitlab旧服务器停机状态下，迁移gitlab服务]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu18.04设置开机启动脚本]]></title>
    <url>%2F2019%2F02%2F28%2Fubuntu-boot-script%2F</url>
    <content type="text"><![CDATA[一、建立rc-local.service文件 1sudo vi /etc/systemd/system/rc-local.service 二、将下列内容复制进rc-local.service文件 1234567891011121314[Unit]Description=/etc/rc.local CompatibilityConditionPathExists=/etc/rc.local [Service]Type=forkingExecStart=/etc/rc.local startTimeoutSec=0StandardOutput=ttyRemainAfterExit=yesSysVStartPriority=99 [Install]WantedBy=multi-user.target 三、创建文件rc.local 1sudo vi /etc/rc.local 四、将下列内容复制进rc.local文件 1234567891011121314#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will &quot;exit 0&quot; on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.echo &quot;看到这行字，说明添加自启动脚本成功。&quot; &gt; /usr/local/test.logexit 0 五、给rc.local加上权限,启用服务 12sudo chmod +x /etc/rc.localsudo systemctl enable rc-local 六、启动服务并检查状态 12sudo systemctl start rc-local.servicesudo systemctl status rc-local.service 七、重启并检查test.log文件 1cat /usr/local/test.log PS:ubuntu16.04直接编辑/etc/rc.local文件即可]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装supervisor]]></title>
    <url>%2F2019%2F01%2F27%2Finstall-supervisor%2F</url>
    <content type="text"><![CDATA[介绍 Supervisor 是一个用 Python 写的进程管理工具，可以很方便的对进程进行启动、停止、重启等操作。 安装 For Ubuntu 安装命令 1$ sudo apt-get install supervisor 配置 安装成功后，会在/etc/supervisor目录下，生成supervisord.conf配置文件。 进程配置会读取/etc/supervisor/conf.d目录下的*.conf配置文件，我们在此目录下创建一个product_celeryd.conf进程配置文件： 12345678910[program:product_celeryd]directory = /webapps/product/command = /webapps/product/env/bin/celery -A licaishi worker -Q productuser = rootstdout_logfile = /webapps/product/logs/product_celeryd.logstderr_logfile = /webapps/product/logs/product_celeryd.logautostart = trueautorestart = truestartsecs = 10stopwaitsecs = 600 启动 接着就可以启动 Supervisord 了： 1$ supervisord supervisorctl 常用命令： 命令 说明 supervisorctl stop program_name 停止某个进程 supervisorctl start program_name 启动某个进程 supervisorctl restart program_name 重启某个进程 supervisorctl stop all 停止全部进程 supervisorctl reload 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 supervisorctl update 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 For Centos 安装 12# yum install python-setuptools# easy_install supervisor 创建配置文件(supervisord.conf） 使用root身份创建一个全局配置文件 12# echo_supervisord_conf &gt; /etc/supervisord.conf# supervisord -c /etc/supervisord.conf 修改配置文件(supervisord.conf） 如果修改了 /etc/supervisord.conf ,需要执行# supervisorctl reload来重新加载配置文件，否则不会生效 12# supervisord 是启动supervisor # supervisorctl 是控制supervisord 打开supervisord.conf 的 [include] 引入 files的配置. 12[include]files = /etc/supervisor/conf.d/*.conf 12[include]files = /etc/supervisor/conf.d/*.conf 需要创建/etc/supervisor/conf.d/ 重启 1# supervisorctl reload]]></content>
      <categories>
        <category>supervisor</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django修改request对象]]></title>
    <url>%2F2018%2F12%2F12%2Fmodify-request%2F</url>
    <content type="text"><![CDATA[Remove immutability: 12345if not request.GET._mutable: request.GET._mutable = True# now you can spoil itrequest.GET['pwd'] = 'iloveyou']]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue跨域配置]]></title>
    <url>%2F2018%2F11%2F30%2Fvue-cross-domain%2F</url>
    <content type="text"><![CDATA[开发环境 如果你使用的是vue-cli3的话，则可按如下配置 在你的项目根目录创建vue.config.js文件 在文件中写入如下配置信息: 123456789101112// 配置proxymodule.exports = &#123; devServer: &#123; proxy: &#123; '/api': &#123; target: 'https://xxxx.xxxxxxxxxx.com', ws: true, changeOrigin: true &#125;, &#125; &#125;&#125;; 参考devserver-proxy 线上环境 线上通过nginx代理,实现跨域 12345678910111213141516171819server &#123; listen 80; server_name www.breakering.com; # 你的域名 location / &#123; index index.html; root /home/jacob/study/licaishi_pc/dist; # vue buil之后dist文件夹位置 try_files $uri $uri/ /index.html =404; # 可以让浏览器在子页面也能刷新，主要是vue-router的路径不是真实路径导致 &#125; # 用/api来访问其他网站的接口，实现跨域 location /api &#123; # 下面三个是跨域的一些设置 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, PUT, PATCH, DELETE, OPTIONS'; # Access-Control-Allow-Headers需要注意，会屏蔽一些headers，部署时需要注意 add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,X-CSRFTOKEN'; proxy_pass https://xxxx.xxxxxxxxxx.com/api; # 其他网站的接口 &#125;&#125;]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue中axios全局设置csrftoken以及Authorization]]></title>
    <url>%2F2018%2F11%2F29%2Fvue-axios-set%2F</url>
    <content type="text"><![CDATA[说在前面 我们都知道，用django做后端服务时，对于post请求提交表单时总是需要csrftoken的验证，那么我们如何在vue中使用axios发起请求时全局在headers里面设置csrftoken呢？以及全局设置Authorization? 设置 其实非常简单，在main.js中设置下即可，示例代码如下: 123456789101112131415161718192021222324252627282930313233343536import Vue from 'vue'import App from './App.vue'import router from './router'import store from './store'import './plugins/axios.js'import './plugins/cookies.js'Vue.config.productionTip = false;new Vue(&#123; router, store, render: h =&gt; h(App), //进入页面时 created() &#123; // 拦截axios请求 this.axios.interceptors.request.use( config =&gt; &#123; // 设置登录验证token const token = this.$store.state.userInfo.Authorization; if (token) &#123; config.headers.Authorization = token; &#125; // 设置csrftoken const csrftoken = this.$cookies.get('csrftoken'); if (csrftoken) &#123; config.headers['X-CSRFTOKEN'] = csrftoken; &#125; return config &#125;, error =&gt; &#123; return Promise.reject(error) &#125;); &#125;&#125;).$mount('#app'); 另外贴下我的store.js: 12345678910111213141516171819202122232425import Vue from 'vue'import Vuex from 'vuex'Vue.use(Vuex);export default new Vuex.Store(&#123; state: &#123; userInfo: &#123; username: "", // 用户名 Authorization: "", // 用户登录的验证Token &#125;, &#125;, mutations: &#123; // 更新用户信息 updateUserInfo(state, userInfo) &#123; state.userInfo.Authorization = userInfo.Authorization; state.userInfo.username = userInfo.username; &#125; &#125;, actions: &#123; updateUserInfo(&#123;commit&#125;, userInfo) &#123; commit('updateUserInfo', userInfo) &#125; &#125;,&#125;) 考虑封装axios 封装进api 创建api文件夹,其中创建一个api.js 编辑plugins下的axios.js 1234567891011121314151617181920212223242526272829303132333435363738394041424344import Vue from 'vue'import axios from 'axios'import VueAxios from 'vue-axios'import store from '../store'Vue.use(VueAxios, axios);// base url// Vue.axios.defaults.baseURL = 'http://127.0.0.1:9001';// 请求超时时间Vue.axios.defaults.timeout = 10000;// 请求拦截器Vue.axios.interceptors.request.use( config =&gt; &#123; // 设置登录验证token const token = store.state.userInfo.Authorization; if (token) &#123; config.headers.Authorization = token; &#125; // 设置csrftoken const csrftoken = Vue.cookies.get('csrftoken'); if (csrftoken) &#123; config.headers['X-CSRFTOKEN'] = csrftoken; &#125; console.log(token, csrftoken); return config &#125;, error =&gt; &#123; return Promise.reject(error) &#125;);// 响应拦截器Vue.axios.interceptors.response.use( // 请求成功 res =&gt; Promise.resolve(res), // 请求失败 error =&gt; &#123; // 请求已发出，但是不在2xx的范围 console.log(error); // 这儿可以用UI插件做个弹窗提醒 return Promise.reject(error); &#125;); 编辑api.js 1234567891011import Vue from 'vue'// 登录接口export const login = data =&gt; Vue.axios.post( '/api/xxxx/login/', data);// 获取新闻列表接口export const getNews = params =&gt; Vue.axios.get( '/api/xxxx/newsflashmaterial/?ordering=-create_time', params); 我的main.js 12345678910import Vue from 'vue'import App from './App.vue'import router from './router'import store from './store'import './plugins/element.js'import './plugins/cookies.js'import './plugins/axios.js'..... 使用 12345678910111213141516171819202122&lt;script&gt; import &#123;login&#125; from "../api/api" export default &#123; name: "Login", data() &#123; return &#123; formLabelAlign: &#123; username: '', password: '' &#125; &#125; &#125;, methods: &#123; submitForm() &#123; login(this.formLabelAlign).then((response) =&gt; &#123; // 登录成功之后的操作 &#125;) &#125;, &#125; &#125;&lt;/script&gt; 完成]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue使用axios]]></title>
    <url>%2F2018%2F11%2F27%2Fvue-use-axios%2F</url>
    <content type="text"><![CDATA[安装 1npm install --save axios vue-axios 引入 123456import Vue from &apos;vue&apos;import axios from &apos;axios&apos;import VueAxios from &apos;vue-axios&apos;axios.defaults.baseURL=&apos;http://localhost:8000&apos;; // 可以设置baseURLVue.use(VueAxios, axios) 使用 1234567getNewsList()&#123; this.axios.get(&apos;api/getNewsList&apos;).then((response)=&gt;&#123; this.newsList=response.data.data; &#125;).catch((response)=&gt;&#123; console.log(response); &#125;)&#125; 参考 vue全局使用axios的方法 vue-axios vue添加axios，并且指定baseurl]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter美化]]></title>
    <url>%2F2018%2F11%2F26%2Fjupyter-beauty%2F</url>
    <content type="text"><![CDATA[jupyterthemes 安装jupyter主题 12345# install jupyterthemespip install jupyterthemes# upgrade to latest versionpip install --upgrade jupyterthemes 使用主题 1jt -t monokai -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -N -T 更多主题设置 jupyterthemes jupyter_contrib_nbextensions 安装jupyter_contrib_nbextensions 1pip install jupyter_contrib_nbextensions 安装js和css文件 1jupyter contrib nbextension install --user 扩展选用 完成]]></content>
      <categories>
        <category>jupyter</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 中 Typora 安装]]></title>
    <url>%2F2018%2F11%2F26%2Fubuntu-typora%2F</url>
    <content type="text"><![CDATA[12345678910111213# optional, but recommendedsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE# add Typora&apos;s repositorysudo add-apt-repository &apos;deb http://typora.io linux/&apos;sudo apt-get update# install typorasudo apt-get install typora 另外推荐安装下Vue的theme，地址:https://theme.typora.io/theme/Vue/]]></content>
      <categories>
        <category>Ubuntu</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab升级]]></title>
    <url>%2F2018%2F11%2F19%2Fgitlab-update%2F</url>
    <content type="text"><![CDATA[更新 GitLab 我们用的是 GitLab Omnibus 7.10.5 版本，查到Doc（6.x.x 等低版本区别对待，详见文档）。 按照文档： 123456# To update to a newer GitLab version, all you have to do is:# Debian/Ubuntusudo apt-get updatesudo apt-get install gitlab-ce# Centos/RHELsudo yum install gitlab-ce 看起来太简单了！事实上，也就是这么简单。 但是，问题来了，sudo apt-get install gilab-ce 默认所用的源是 packages-gitlab-com.s3.amazonaws.com，然后你懂的，被墙了！ 解决办法有两个： 给 apt 加代理； 换源。 1). 给 apt 加代理 考虑到换源可能产生其他的依赖问题，先尝试 加代理。结果是加了代理还是不行！原因可能是代理连接速度问题，总是超时。 这里参考的是 打造Linux 终端翻墙环境 使用 shadowsocks + privoxy 。 2). 换源解决！ Docs 里已经有声明其实： 首先，添加信任 GitLab 里的 GPG 公钥： 1curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null 然后把 /etc/apt/sources.list.d/gitlab_gitlab-ce.list 文件中默认的源换成 deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu trusty main 最后： 12sudo updatesudo apt-get install gitlab-ce 安装完成！ 对于更新版本跨度较大的情况 1). 关闭部分gitlab服务 升级之前，我们首先要关闭gitlab部分服务，如下： 123gitlab-ctl stop unicorngitlab-ctl stop sidekiqgitlab-ctl stop nginx 2). 选择要升级的版本 版本查看地址 然后执行命令： 1apt-get install gitlab-ce=11.0.3-ce.0 其中11.0.3替换为你要升级的版本号。 ps:版本跨度过大，请务必一个小版本一个小版本的更新 另外，附上一次成功的更新过程对应的版本号： 9.2.5--&gt;9.5.6--&gt;10.0.6--&gt;10.8.5--&gt;11.0.3 3). 重启gitlab 12gitlab-ctl reconfiguregitlab-ctl restart References: http://www.a-ho.com/2016/01/16/打造Linux-终端翻墙环境/ https://about.gitlab.com/downloads/#ubuntu1404 https://mirror.tuna.tsinghua.edu.cn/help/gitlab-ce/ http://docs.gitlab.com/omnibus/update/README.html https://about.gitlab.com/upgrade-to-package-repository/ https://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/trusty/gitlab-ce_8.9.5-ce.0_amd64.deb https://www.ilanni.com/?p=13917 https://www.58jb.com/html/189.html]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab备份与恢复]]></title>
    <url>%2F2018%2F11%2F19%2Fgitlab-backup%2F</url>
    <content type="text"><![CDATA[一、 备份gitlab gitlab的备份比较简单，我们直接使用gitlab本身提供的命令进行备份即可。 1.1 通过gitlab-rake命令备份gitlab gitlab提供的备份命令为gitlab-rake，备份命令使用如下: 1gitlab-rake gitlab:backup:create 该命令会备份gitlab仓库、数据库、用户、用户组、用户密钥、权限等信息。 备份完成后备份文件会出现在/var/opt/gitlab/backups/ 当然备份的位置可以更换,使用如下命令： 1vim /etc/gitlab/gitlab.rb 修改上图backup_path的值即可，之后使用gitlab-ctl reconfigure使得配置生效 ps：备份文件的名称中1537261122_2018_09_18_9.2.5是此次备份的编号。该编号我们会在后续恢复gitlab数据使用到。 1.2 定时备份gitlab 如果要使ｇitlab自动进行备份的话，我们可以通过crontab命令来实现自动备份。强烈建议使用系统crontab命令，而不是用户crontab。 以实现每天凌晨4点进行一次自动备份为例，系统的crontab配置如下: 1vim /etc/crontab 0 4 * * * root /opt/gitlab/bin/gitlab-rake gitlab:backup:create CRON=1 然后重启crontab服务，如下： 1systemctl restart crond 1.3 保留部分备份文件 随着时间的推移gitlab备份文件越来越多，服务器的磁盘空间也不够大。 此时我们就要删除部分旧的备份文件，gitlab也提供了删除旧的备份文件功能。该功能在gitlab的配置文件中，进行配置即可。 在此以保留7天之前的备份文件为例，如下： 1vim /etc/gitlab/gitlab.rb gitlab_rails[‘backup_keep_time’] = 604800 其中backup_keep_time是以秒为单位进行计算的，然后执行命令gitlab-ctl reconfigure即可。 二、gitlab仓库恢复 要验证gitlab备份的有效性，我们可以把该备份文件复制到已经安装好gitlab服务器的/var/opt/gitlab/backups/目录下。然后进行数据恢复，最后访问并查看其数据完整性即可。 通过gitlab备份文件可以恢复gitlab所有的信息，包括仓库、数据库、用户、用户组、用户密钥、权限等信息。 ps：新服务器上的gitlab的版本号必须与创建备份时的gitlab版本号相同。 gitlab数据恢复比较简单，具体步骤如下： 2.1 停止相关数据连接服务 在gitlab服务器上停止相关数据连接服务，命令如下： 12gitlab-ctl stop unicorngitlab-ctl stop sidekiq 2.2 恢复gitlab仓库 现在我们要从1537261122_2018_09_18_9.2.5这个备份编号中，恢复数据，命令如下： 1gitlab-rake gitlab:backup:restore BACKUP=1537261122_2018_09_18_9.2.5 如果出现多个done的信息，说明整个gitlab数据就已经正常恢复完毕。 2.3 启动gitlab服务 恢复完毕以后，我们现在来启动gitlab，使用以下命令： 1gitlab-ctl start 强烈建议：重启该新服务器。 三、References: gitlab的备份与恢复]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用pipenv管理python项目]]></title>
    <url>%2F2018%2F11%2F19%2Fpipenv%2F</url>
    <content type="text"><![CDATA[安装pipenv 1pip install pipenv 项目初始化 12cd your_projectPIPENV_VENV_IN_PROJECT=true pipenv --python=3.6 将在项目目录中创建新文件Pipfile和一个虚拟环境.venv, --python=3.6则是使用python3.6来创建虚拟环境,PIPENV_VENV_IN_PROJECT=true则是让虚拟环境创建在该项目目录下，方便管理。 如果你添加–two或–three标志到上面的最后一个命令，它分别使用Python 2或3来初始化你的项目。 否则将使用默认版本的Python。 激活开发环境 1pipenv shell 退出开发环境 1exit 使用说明(pipenv -h) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Usage: pipenv [OPTIONS] COMMAND [ARGS]...Options: --where Output project home information. --venv Output virtualenv information. --py Output Python interpreter information. --envs Output Environment Variable options. --rm Remove the virtualenv. --bare Minimal output. --completion Output completion (to be eval'd). --man Display manpage. --support Output diagnostic information for use in GitHub issues. --site-packages Enable site-packages for the virtualenv. --python TEXT Specify which version of Python virtualenv should use. --three / --two Use Python 3/2 when creating virtualenv. --clear Clears caches (pipenv, pip, and pip-tools). -v, --verbose Verbose mode. --pypi-mirror TEXT Specify a PyPI mirror. --version Show the version and exit. -h, --help Show this message and exit.Usage Examples: Create a new project using Python 3.7, specifically: $ pipenv --python 3.7 Remove project virtualenv (inferred from current directory): $ pipenv --rm Install all dependencies for a project (including dev): $ pipenv install --dev Create a lockfile containing pre-releases: $ pipenv lock --pre Show a graph of your installed dependencies: $ pipenv graph Check your installed dependencies for security vulnerabilities: $ pipenv check Install a local setup.py into your virtual environment/Pipfile: $ pipenv install -e . Use a lower-level pip command: $ pipenv run pip freezeCommands: check Checks for security vulnerabilities and against PEP 508 markers provided in Pipfile. clean Uninstalls all packages not specified in Pipfile.lock. graph Displays currently-installed dependency graph information. install Installs provided packages and adds them to Pipfile, or (if no packages are given), installs all packages from Pipfile. lock Generates Pipfile.lock. open View a given module in your editor. run Spawns a command installed into the virtualenv. shell Spawns a shell within the virtualenv. sync Installs all packages specified in Pipfile.lock. uninstall Un-installs a provided package and removes it from Pipfile. update Runs lock, then sync. 总结 pipenv使得开发和管理项目包的过程变成的简单，让我们尽早使用起来吧。 一些错误 1234... File &quot;/usr/lib/python3.7/site-packages/pipenv/vendor/pythonfinder/models/python.py&quot;, line 70, in get_version_order version_order = [versions[v] for v in parse_pyenv_version_order()]TypeError: &apos;NoneType&apos; object is not iterable 这时可以使用下面的命令解决: 1pyenv global 3.7.1 3.7.1换成你用pyenv安装过的环境]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django常见错误解决办法]]></title>
    <url>%2F2018%2F11%2F19%2Fdjango-errors%2F</url>
    <content type="text"><![CDATA[ProgrammingError: relation “default_cache_table” does not exist 123......django.db.utils.ProgrammingError: relation &quot;default_cache_table&quot; does not existLINE 1: SELECT cache_key, value, expires FROM &quot;default_cache_table&quot; WHERE ca... 类似上述这种错误，可以用下面这句命令解决: 1python manage.py createcachetable]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL允许被远程访问]]></title>
    <url>%2F2018%2F11%2F19%2Fpostgresql-remote%2F</url>
    <content type="text"><![CDATA[1.修改postgresql.conf postgresql.conf存放位置在/etc/postgresql/9.x/main下，这里的x取决于你安装PostgreSQL的版本号，编辑或添加下面一行，使PostgreSQL可以接受来自任意IP的连接请求。 1listen_addresses = &apos;*&apos; 2.修改pg_hba.conf 修改pg_hba.conf位置与postgresql.conf相同，虽然上面配置允许任意地址连接PostgreSQL，但是这在pg中还不够，我们还需在pg_hba.conf中配置服务端允许的认证方式。任意编辑器打开该文件，编辑或添加下面一行。 12# TYPE DATABASE USER CIDR-ADDRESS METHODhost all all 0.0.0.0/0 md5 默认pg只允许本机通过密码认证登录，修改为上面内容后即可以对任意IP访问进行密码验证。对照上面的注释可以很容易搞明白每列的含义，具体的支持项可以查阅文末参考引用。 完成上两项配置后执行sudo service postgresql restart重启PostgreSQL服务后，允许外网访问的配置就算生效了。]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-celery实现定时任务]]></title>
    <url>%2F2018%2F11%2F16%2Fdjango-celery%2F</url>
    <content type="text"><![CDATA[介绍 我们知道celery可以直接用在django项目中，但是配置稍微繁琐，还有添加定时任务需要重启celery beat进程，实在蛋疼，好在找到了django-celery这个模块，话不多说，让我们用起来吧。 安装和配置 安装还是很简单的，直接pip即可 1pip install django-clery 此时会将一些依赖库一并安装，比如celery等 接下来是django项目中的配置，在settings中配置如下: 1234567891011121314# INSTALLED_APPS中加入djceleryINSTALLED_APPS = [ .... &apos;djcelery&apos;]# 配置djcelery相关参数，ResultStore默认存储在数据库可不必重写 ，djcelery.setup_loader()BROKER_URL = &apos;redis://127.0.0.1:6379/8&apos; # 配置你的redis地址和库# 使用和Django一样的时区CELERY_TIMEZONE = TIME_ZONE# 以上为基本配置，以下为周期性任务定义CELERYBEAT_SCHEDULER = &apos;djcelery.schedulers.DatabaseScheduler&apos; 同步数据库 1python manage.py migrate 创建task 在你的app下面创建一个tasks.py文件，文件名必须一致，django-celery默认情况下会自动从各个app中寻找该模块。 12345from celery import task@task()def send_msg(msg): print(msg) 注意：task装饰器的name参数最好和函数名一致或者干脆不指定;最好不指定，这样下方分发任务时好统一处理。 创建定时任务 接下来我们就可以在Django admin中创建定时任务了 启动beat和worker 1python manage.py celery worker -l info 1python manage.py celery beat 之后就可以观察日志了，另外可以使用supervisor来管理这两个进程。 利用queue分发任务 在settings中增加如下配置: 1234567891011121314# 定义任务对应的queueclass TasksRouter(object): @classmethod def route_for_task(cls, task, args=None, kwargs=None): task_routes = &#123; &apos;algorithm.product.tasks.*&apos;: &#123;&apos;queue&apos;: &apos;product&apos;&#125;, &apos;algorithm.material.tasks.*&apos;: &#123;&apos;queue&apos;: &apos;material&apos;&#125;, &#125; for route_key in task_routes: if re.search(route_key, task): return task_routes[route_key]CELERY_ROUTES = (TasksRouter(), ) 配置完成之后，启动beat和worker 1python manage.py celery beat beat会实时检测任务的变化，在django admin界面对任务进行操作，均会刷新该进程，使得分派任务变得非常简单。 1python manage.py celery worker -Q product 上述命令启动的worker只会监测并执行product这个queue中的任务，即只执行algorithm.product.tasks下面的任务。同理python manage.py celery worker -Q material只执行algorithm.material.tasks下面的任务。 另外queue可以添加多个,例如python manage.py celery worker -Q product,material。 若要不区分queue执行所有任务，只需python manage.py celery worker即可,但不推荐,开启任务分发之后，最好分开执行，日志方面也更好排查。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux在局域网如何通过hostname获取其ip]]></title>
    <url>%2F2018%2F11%2F16%2Flinux-hostname_to_ip%2F</url>
    <content type="text"><![CDATA[只需要hostname固定，就可以在局域网通过ping hostname.local来获取其ip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Django中实现queryset级别缓存]]></title>
    <url>%2F2018%2F11%2F16%2Fdjango-queryset-cache%2F</url>
    <content type="text"><![CDATA[介绍 实现queryset级别的缓存，不是view层面的，相当于缓存sql查询结果。 使用 首先在你的django项目中安装依赖的模块 1pip install django-cache-machine 创建queryset_cache.py文件,文件内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#! /usr/bin/env python# -*- coding: utf-8 -*-# __author__ = "Breakering"# Date: 18-8-29"""依赖django-cache-machine，并在此基础上实现了轻松切换使用queryset级别缓存以及count等缓存"""import contextlibfrom caching import configfrom caching.base import CachingQuerySet, cached_withfrom django.db.models.sql import querydef queryset_cache_decorator(always_cached=True): """queryset级别缓存的装饰器，可以使得queryset直接从缓存中获取数据""" def wrapper(func): def inner(self, *args, **kwargs): queryset = func(self, *args, **kwargs) if always_cached: # 此装饰器默认从cache中获取数据 queryset = queryset.from_cache() else: with contextlib.suppress(Exception): queryset_cache_time = self.request.query_params.get('queryset_cache_time', '') if queryset_cache_time and queryset_cache_time.isdigit(): queryset = queryset.from_cache(int(queryset_cache_time)) return queryset return inner return wrapperdef queryset_cache_count_decorator(always_cached=True): """queryset count缓存的装饰器，可以使得queryset直接从缓存中获取count的值""" def wrapper(func): def inner(self, *args, **kwargs): queryset = func(self, *args, **kwargs) if always_cached: # 此装饰器默认从cache中获取数据 queryset = queryset.cache_count() else: with contextlib.suppress(Exception): queryset_cache_time = self.request.query_params.get('queryset_cache_time', '') if queryset_cache_time and queryset_cache_time.isdigit(): queryset = queryset.cache_count(int(queryset_cache_time)) return queryset return inner return wrapperclass CachedQuerySet(CachingQuerySet): """ Return queryset from cache if query_key in cache """ def __init__(self, *args, **kwargs): super(CachedQuerySet, self).__init__(*args, **kwargs) self.timeout = config.NO_CACHE # 默认直接从数据库取数据 self.cache_count_timeout = config.NO_CACHE # 自定义queryset count的缓存时间 def _clone(self, *args, **kw): qs = super(CachedQuerySet, self)._clone(*args, **kw) qs.cache_count_timeout = self.cache_count_timeout return qs def from_cache(self, timeout=60*60): """在queryset中调用此函数则是从缓存中获取,且调用之后返回的仍是queryset""" self.timeout = timeout return self._clone() def cache_count(self, cache_count_timeout=60*60): """实现queryset count的缓存,且调用之后返回的仍是queryset""" self.cache_count_timeout = cache_count_timeout return self._clone() # todo values目前的实现方式有BUG，现已取消 # def values(self, *fields, **expressions): # """rewrite queryset's values""" # if self.timeout == config.NO_CACHE: # 默认情况下values直接从数据库获取数据 # return super(CachedQuerySet, self).values(*fields, **expressions) # # clone = self._clone() # clone.query.set_values(fields) # key = make_key('values:&#123;key&#125;'.format(key=clone.query_key())) # val = cache.get(key) # if val is None: # val = super(CachedQuerySet, self).values(*fields, **expressions) # cache.set(key, val, self.timeout) # return val def count(self): """自定义queryset的count""" super_count = super(CachingQuerySet, self).count try: query_string = 'count:%s' % self.query_key() except query.EmptyResultSet: return 0 if self.cache_count_timeout: return cached_with(self, super_count, query_string, self.cache_count_timeout) elif self.timeout == config.NO_CACHE or config.TIMEOUT == config.NO_CACHE: return super_count() else: return cached_with(self, super_count, query_string, config.TIMEOUT) 改造您的model 1234567891011from django.db import modelsfrom queryset_cache import CachedQuerySetfrom caching.base import CachingMixinclass ModelClassManger(models.Manager): def get_queryset(self): return CachedQuerySet(self.model) class ModelClass(CachingMixin, models.Model): objects = ModelClassManger() view层只需在get_queryset上加上装饰器即可 1234@queryset_cache_count_decorator()@queryset_cache_decorator()def get_queryset(self): pass 如果添加了always_cached=False 1234@queryset_cache_count_decorator(always_cached=False)@queryset_cache_decorator(always_cached=False)def get_queryset(self): pass 则需要在query参数中加上queryset_cache_time=180,参数后面的数字即为缓存的时间。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo同步]]></title>
    <url>%2F2018%2F11%2F15%2Fhexo-sync%2F</url>
    <content type="text"><![CDATA[环境搭建 安装Node.js 用来生成静态页面, 到Node.js官网，下载最新版本, 根据提示一路安装即可 安装Git 1sudo apt-get install git 安装Hexo 当Node.js和Git都安装好后就可以正式安装Hexo了，终端执行如下命令： 1sudo npm install -g hexo 克隆hexo分支 1git clone -b hexo https://github.com/Breakering/breakering.github.io.git 进入breakering.github.io.git 创建博客 1hexo n &apos;博客名&apos; 发表博客 1hexo d -g 主题配置更新相关 需要先清空缓存 1hexo clean 然后进行部署操作 1hexo d -g 一些问题 报错一: 若执行命令hexo deploy仍然报错：无法连接git或找不到git，则执行如下命令来安装hexo-deployer-git： 1npm install hexo-deployer-git --save 报错二: 若执行命令hexo d报以下错误: 123ERROR Plugin load failed: hexo-server //或者类似的错误 ERROR Plugin load failed: hexo-renderer-sass 则执行响应的命令: 123sudo npm install hexo-server//或者sudo npm install hexo-renderer-sass]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网穿透frp]]></title>
    <url>%2F2018%2F09%2F28%2Ffrp%2F</url>
    <content type="text"><![CDATA[一、内网穿透原理 简单地说，内网穿透依赖于 NAT 原理，根据 NAT 设备不同大致可分为以下 4 大类(前3种NAT类型可统称为cone类型)： 全克隆(Full Cone)：NAT 把所有来自相同内部 IP 地址和端口的请求映射到相同的外部 IP 地址和端口上，任何一个外部主机均可通过该映射反向发送 IP 包到该内部主机 限制性克隆(Restricted Cone)：NAT 把所有来自相同内部 IP 地址和端口的请求映射到相同的外部 IP 地址和端口；但是，只有当内部主机先给 IP 地址为 X 的外部主机发送 IP 包时，该外部主机才能向该内部主机发送 IP 包 端口限制性克隆(Port Restricted Cone)：端口限制性克隆与限制性克隆类似，只是多了端口号的限制，即只有内部主机先向 IP 地址为 X，端口号为 P 的外部主机发送1个 IP 包,该外部主机才能够把源端口号为 P 的 IP 包发送给该内部主机 对称式NAT(Symmetric NAT)：这种类型的 NAT 与上述3种类型的不同，在于当同一内部主机使用相同的端口与不同地址的外部主机进行通信时， NAT 对该内部主机的映射会有所不同；对称式 NAT 不保证所有会话中的私有地址和公开 IP 之间绑定的一致性；相反，它为每个新的会话分配一个新的端口号；导致此种 NAT 根本没法穿透 内网穿透的作用就是利用以上规则，创建一条从外部服务器到内部设备的 “隧道”，具体的 NAT 原理等可参考 内网打洞、网络地址转换NAT原理。 二、环境准备 实际上根据以上 NAT 规则，基本上大部分家用设备和运营商上级路由等都在前三种规则之中，所以只需要借助成熟的内网穿透工具即可，以下为本次穿透环境 最新版本 frp 一台公网 VPS 服务器 内网一台服务器，最好 Linux 系统 三、服务端搭建 服务器作为公网访问唯一的固定地址，即作为 server 端；内网客户端作为 client 端，会主动向 server 端创建连接，此时再从 server 端反向发送数据即可实现内网穿透 3.1). 下载并解压frp 可以查看releases获取最新的版本,选好版本之后使用以下命令: 123wget https://github.com/fatedier/frp/releases/download/v0.21.0/frp_0.21.0_linux_amd64.tar.gztar -zxvf frp_0.21.0_linux_amd64.tar.gzcd frp_0.21.0_linux_amd64 3.2). 编辑frps.ini 1234567891011121314151617181920212223242526272829303132333435[common] # frp 监听地址bind_addr = 0.0.0.0bind_port = 7000# 如果需要代理 web(http) 服务，则开启此端口vhost_http_port = 8080vhost_https_port = 4443# frp 控制面板dashboard_port = 7500dashboard_user = userdashboard_pwd = pwd# 默认日志输出位置(这里输出到标准输出)log_file = /tmp/frps.log# 日志级别，支持: debug, info, warn, errorlog_level = infolog_max_days = 3# 是否开启特权模式(特权模式下，客户端更改配置无需更新服务端)privilege_mode = true# 授权 token 建议随机生成privilege_token = cc23*********************d072734# 特权模式下允许分配的端口(避免端口滥用)privilege_allow_ports = 4000-50000# 后端连接池最大连接数量max_pool_count = 100# 口令超时时间authentication_timeout = 900# 子域名(特权模式下将 *.xxxx.com 解析到公网服务器)subdomain_host = xxxx.com 其他具体配置说明请参考frp README 文档 3.3). 启动frp server 设置完成后执行 ./frps -c frps.ini 启动即可 ps:当然也可以使用supervisor来管理 四、客户端配置 客户端作为发起链接的主动方，只需要正确配置服务器地址，以及要映射客户端的哪些服务端口等即可 4.1). 下载并解压frp 123wget https://github.com/fatedier/frp/releases/download/v0.21.0/frp_0.21.0_linux_amd64.tar.gztar -zxvf frp_0.21.0_linux_amd64.tar.gzcd frp_0.21.0_linux_amd64 4.2). 编辑frpc.ini 123456789101112131415161718192021222324252627[common]server_addr = 127.0.0.1server_port = 7000# console or real logFile path like ./frpc.loglog_file = /tmp/frpc.log# debug, info, warn, errorlog_level = debuglog_max_days = 3# 特权模式，要和服务器端的配置一致privilege_token = cc23*********************d072734[gitlab]type = httplocal_port = 80subdomain = gitlab # 这样只要访问http://gitlab.xxxx.com:8080即可访问到该客户端的gitlab服务use_gzip = true[gitlab_ssh]type = tcp local_ip = 127.0.0.1local_port = 22remote_port = 8081 其他具体配置说明请参考frp README 文档 4.3). 启动frp client 设置完成后执行 ./frpc -c frpc.ini 启动即可 ps:当然也可以使用supervisor来管理 五、测试 服务端和客户端同时开启完成后，即可访问 http://127.0.0.1:7500 进入 frp 控制面板，如下 此时通过 ssh root@127.0.0.1 -p 8081 即可ssh到gitlab，通过访问http://gitlab.xxxx.com:8080 即可访问gitlab服务 六、GitLab通过frp代理 通过上述配置，确实可以通过 http://gitlab.xxxx.com:8080 访问gitlab服务,但是你会发现缺少静态文件,因为gitlab的静态文件是nginx代理的，走的tcp协议,需要一种解决方案。 经测试可以在gitlab服务器配置如下nginx解决 1234567891011server &#123; listen 80; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; location /assets &#123; alias /opt/gitlab/embedded/service/gitlab-rails/public/assets; &#125;&#125; 公网服务器nginx如下设置 1234567server &#123; listen 80; server_name gitlab.xxxx.com; location / &#123; proxy_pass http://gitlab.geekfinancer.com:8080; &#125;&#125; 这样即可通过 http://gitlab.xxxx.com 正常访问内网的gitlab了 但是这样还没结束，你会发现外网通过git clone http://gitlab.xxxx.com/zhuqian/licaishi.git ,根本没法正常克隆仓库，那有啥用啊，别急，咋们还可以用ssh方式啊。 上面我们已经配置gitlab的22端口映射到服务器的8081端口了，所以可以这样克隆: 123git clone ssh://git@127.0.0.1:8081/zhuqian/licaishi.git# 或者git clone ssh://git@gitlab.xxxx.com:8081/zhuqian/licaishi.git 对于pip install的话，可以这样： 123pip install git+ssh://git@127.0.0.1:8081/zhuqian/algorithm.git# 或者pip install git+ssh://git@gitlab.xxxx.com:8081/zhuqian/algorithm.git 你以为就这样完了，还没有，我们想要直接能在gitlab项目首页直接能够显示git访问方法，效果如下: 要实现此效果，只需配置下/etc/gitlab/gitlab.rb即可： 123456...external_url &apos;http://gitlab.xxxx.com&apos;...gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 8081... 另外需要注意下nginx['listen_addresses'] = ['192.168.10.60']，需要对应到本地的ip地址 配置完之后: 1gitlab-ctl reconfigure 然后通过域名访问gitlab即可实现上述效果了，只不过http方式目前还无法解决。 七、由mtu引起的无法访问的问题 如果frp的admin界面一切正常，但是就是无法获取数据 那么极有可能是你本地的网络最大分片小于服务器的最大分片，导致数据无法发送出去,解决办法是减小服务器的mtu: 1sudo ifconfig eth0 mtu 1000 up 其他修改mtu的方式请自行google。 八、References: 利用 frp 进行内网穿透]]></content>
      <categories>
        <category>内网穿透</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo初识]]></title>
    <url>%2F2018%2F09%2F28%2Fhexo-start%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
