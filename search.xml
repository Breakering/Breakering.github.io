<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[django修改request对象]]></title>
    <url>%2F2018%2F12%2F12%2Fdjango-modify-request%2F</url>
    <content type="text"><![CDATA[Remove immutability: 12345if not request.GET._mutable: request.GET._mutable = True# now you can spoil itrequest.GET['pwd'] = 'iloveyou']]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue跨域配置]]></title>
    <url>%2F2018%2F11%2F30%2Fvue-cross-domain%2F</url>
    <content type="text"><![CDATA[开发环境如果你使用的是vue-cli3的话，则可按如下配置 在你的项目根目录创建vue.config.js文件 在文件中写入如下配置信息: 123456789101112// 配置proxymodule.exports = &#123; devServer: &#123; proxy: &#123; '/api': &#123; target: 'https://xxxx.xxxxxxxxxx.com', ws: true, changeOrigin: true &#125;, &#125; &#125;&#125;; 参考devserver-proxy 线上环境线上通过nginx代理,实现跨域 12345678910111213141516171819server &#123; listen 80; server_name www.breakering.com; # 你的域名 location / &#123; index index.html; root /home/jacob/study/licaishi_pc/dist; # vue buil之后dist文件夹位置 try_files $uri $uri/ /index.html; # 可以让浏览器在子页面也能刷新，主要是vue-router的路径不是真实路径导致 &#125; # 用/api来访问其他网站的接口，实现跨域 location /api &#123; # 下面三个是跨域的一些设置 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, PUT, PATCH, DELETE, OPTIONS'; # Access-Control-Allow-Headers需要注意，会屏蔽一些headers，部署时需要注意 add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,X-CSRFTOKEN'; proxy_pass https://xxxx.xxxxxxxxxx.com/api; # 其他网站的接口 &#125;&#125;]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue中axios全局设置csrftoken以及Authorization]]></title>
    <url>%2F2018%2F11%2F29%2Fvue-axios-set%2F</url>
    <content type="text"><![CDATA[说在前面我们都知道，用django做后端服务时，对于post请求提交表单时总是需要csrftoken的验证，那么我们如何在vue中使用axios发起请求时全局在headers里面设置csrftoken呢？以及全局设置Authorization? 设置其实非常简单，在main.js中设置下即可，示例代码如下: 123456789101112131415161718192021222324252627282930313233343536import Vue from 'vue'import App from './App.vue'import router from './router'import store from './store'import './plugins/axios.js'import './plugins/cookies.js'Vue.config.productionTip = false;new Vue(&#123; router, store, render: h =&gt; h(App), //进入页面时 created() &#123; // 拦截axios请求 this.axios.interceptors.request.use( config =&gt; &#123; // 设置登录验证token const token = this.$store.state.userInfo.Authorization; if (token) &#123; config.headers.Authorization = token; &#125; // 设置csrftoken const csrftoken = this.$cookies.get('csrftoken'); if (csrftoken) &#123; config.headers['X-CSRFTOKEN'] = csrftoken; &#125; return config &#125;, error =&gt; &#123; return Promise.reject(error) &#125;); &#125;&#125;).$mount('#app'); 另外贴下我的store.js: 12345678910111213141516171819202122232425import Vue from 'vue'import Vuex from 'vuex'Vue.use(Vuex);export default new Vuex.Store(&#123; state: &#123; userInfo: &#123; username: "", // 用户名 Authorization: "", // 用户登录的验证Token &#125;, &#125;, mutations: &#123; // 更新用户信息 updateUserInfo(state, userInfo) &#123; state.userInfo.Authorization = userInfo.Authorization; state.userInfo.username = userInfo.username; &#125; &#125;, actions: &#123; updateUserInfo(&#123;commit&#125;, userInfo) &#123; commit('updateUserInfo', userInfo) &#125; &#125;,&#125;) 考虑封装axios封装进api 创建api文件夹,其中创建一个api.js 编辑plugins下的axios.js 1234567891011121314151617181920212223242526272829303132333435363738394041424344import Vue from 'vue'import axios from 'axios'import VueAxios from 'vue-axios'import store from '../store'Vue.use(VueAxios, axios);// base url// Vue.axios.defaults.baseURL = 'http://127.0.0.1:9001';// 请求超时时间Vue.axios.defaults.timeout = 10000;// 请求拦截器Vue.axios.interceptors.request.use( config =&gt; &#123; // 设置登录验证token const token = store.state.userInfo.Authorization; if (token) &#123; config.headers.Authorization = token; &#125; // 设置csrftoken const csrftoken = Vue.cookies.get('csrftoken'); if (csrftoken) &#123; config.headers['X-CSRFTOKEN'] = csrftoken; &#125; console.log(token, csrftoken); return config &#125;, error =&gt; &#123; return Promise.reject(error) &#125;);// 响应拦截器Vue.axios.interceptors.response.use( // 请求成功 res =&gt; Promise.resolve(res), // 请求失败 error =&gt; &#123; // 请求已发出，但是不在2xx的范围 console.log(error); // 这儿可以用UI插件做个弹窗提醒 return Promise.reject(error); &#125;); 编辑api.js 1234567891011import Vue from 'vue'// 登录接口export const login = data =&gt; Vue.axios.post( '/api/xxxx/login/', data);// 获取新闻列表接口export const getNews = params =&gt; Vue.axios.get( '/api/xxxx/newsflashmaterial/?ordering=-create_time', params); 我的main.js 12345678910import Vue from 'vue'import App from './App.vue'import router from './router'import store from './store'import './plugins/element.js'import './plugins/cookies.js'import './plugins/axios.js'..... 使用 12345678910111213141516171819202122&lt;script&gt; import &#123;login&#125; from "../api/api" export default &#123; name: "Login", data() &#123; return &#123; formLabelAlign: &#123; username: '', password: '' &#125; &#125; &#125;, methods: &#123; submitForm() &#123; login(this.formLabelAlign).then((response) =&gt; &#123; // 登录成功之后的操作 &#125;) &#125;, &#125; &#125;&lt;/script&gt; 完成]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue使用axios]]></title>
    <url>%2F2018%2F11%2F27%2Fvue-use-axios%2F</url>
    <content type="text"><![CDATA[安装1npm install --save axios vue-axios 引入123456import Vue from &apos;vue&apos;import axios from &apos;axios&apos;import VueAxios from &apos;vue-axios&apos;axios.defaults.baseURL=&apos;http://localhost:8000&apos;; // 可以设置baseURLVue.use(VueAxios, axios) 使用1234567getNewsList()&#123; this.axios.get(&apos;api/getNewsList&apos;).then((response)=&gt;&#123; this.newsList=response.data.data; &#125;).catch((response)=&gt;&#123; console.log(response); &#125;)&#125; 参考vue全局使用axios的方法 vue-axios vue添加axios，并且指定baseurl]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter美化]]></title>
    <url>%2F2018%2F11%2F26%2Fjupyter-beauty%2F</url>
    <content type="text"><![CDATA[jupyterthemes安装jupyter主题12345# install jupyterthemespip install jupyterthemes# upgrade to latest versionpip install --upgrade jupyterthemes 使用主题1jt -t monokai -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -N -T 更多主题设置jupyterthemes jupyter_contrib_nbextensions安装jupyter_contrib_nbextensions1pip install jupyter_contrib_nbextensions 安装js和css文件1jupyter contrib nbextension install --user 扩展选用 完成]]></content>
      <categories>
        <category>jupyter</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 中 Typora 安装]]></title>
    <url>%2F2018%2F11%2F26%2Fubuntu-typora%2F</url>
    <content type="text"><![CDATA[12345678910111213# optional, but recommendedsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE# add Typora&apos;s repositorysudo add-apt-repository &apos;deb http://typora.io linux/&apos;sudo apt-get update# install typorasudo apt-get install typora 另外推荐安装下Vue的theme，地址:https://theme.typora.io/theme/Vue/]]></content>
      <categories>
        <category>Ubuntu</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab升级]]></title>
    <url>%2F2018%2F11%2F19%2Fgitlab-update%2F</url>
    <content type="text"><![CDATA[更新 GitLab 我们用的是 GitLab Omnibus 7.10.5 版本，查到Doc（6.x.x 等低版本区别对待，详见文档）。按照文档：123456# To update to a newer GitLab version, all you have to do is:# Debian/Ubuntusudo apt-get updatesudo apt-get install gitlab-ce# Centos/RHELsudo yum install gitlab-ce 看起来太简单了！事实上，也就是这么简单。 但是，问题来了，sudo apt-get install gilab-ce 默认所用的源是 packages-gitlab-com.s3.amazonaws.com，然后你懂的，被墙了！ 解决办法有两个： 给 apt 加代理； 换源。 1). 给 apt 加代理考虑到换源可能产生其他的依赖问题，先尝试 加代理。结果是加了代理还是不行！原因可能是代理连接速度问题，总是超时。 这里参考的是 打造Linux 终端翻墙环境 使用 shadowsocks + privoxy 。 2). 换源解决！Docs 里已经有声明其实： 首先，添加信任 GitLab 里的 GPG 公钥： 1curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null 然后把 /etc/apt/sources.list.d/gitlab_gitlab-ce.list 文件中默认的源换成 deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu trusty main 最后： 12sudo updatesudo apt-get install gitlab-ce 安装完成！ 对于更新版本跨度较大的情况1). 关闭部分gitlab服务升级之前，我们首先要关闭gitlab部分服务，如下： 123gitlab-ctl stop unicorngitlab-ctl stop sidekiqgitlab-ctl stop nginx 2). 选择要升级的版本版本查看地址 然后执行命令： 1apt-get install gitlab-ce=11.0.3-ce.0 其中11.0.3替换为你要升级的版本号。 ps:版本跨度过大，请务必一个小版本一个小版本的更新 另外，附上一次成功的更新过程对应的版本号： 9.2.5--&gt;9.5.6--&gt;10.0.6--&gt;10.8.5--&gt;11.0.3 3). 重启gitlab12gitlab-ctl reconfiguregitlab-ctl restart References: http://www.a-ho.com/2016/01/16/%E6%89%93%E9%80%A0Linux-%E7%BB%88%E7%AB%AF%E7%BF%BB%E5%A2%99%E7%8E%AF%E5%A2%83/ https://about.gitlab.com/downloads/#ubuntu1404 https://mirror.tuna.tsinghua.edu.cn/help/gitlab-ce/ http://docs.gitlab.com/omnibus/update/README.html https://about.gitlab.com/upgrade-to-package-repository/ https://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/trusty/gitlab-ce_8.9.5-ce.0_amd64.deb https://www.ilanni.com/?p=13917 https://www.58jb.com/html/189.html]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab备份与恢复]]></title>
    <url>%2F2018%2F11%2F19%2Fgitlab-backup%2F</url>
    <content type="text"><![CDATA[一、 备份gitlabgitlab的备份比较简单，我们直接使用gitlab本身提供的命令进行备份即可。 1.1 通过gitlab-rake命令备份gitlabgitlab提供的备份命令为gitlab-rake，备份命令使用如下: 1gitlab-rake gitlab:backup:create 该命令会备份gitlab仓库、数据库、用户、用户组、用户密钥、权限等信息。 备份完成后备份文件会出现在/var/opt/gitlab/backups/ 当然备份的位置可以更换,使用如下命令： 1vim /etc/gitlab/gitlab.rb 修改上图backup_path的值即可，之后使用gitlab-ctl reconfigure使得配置生效 ps：备份文件的名称中1537261122_2018_09_18_9.2.5是此次备份的编号。该编号我们会在后续恢复gitlab数据使用到。 1.2 定时备份gitlab如果要使ｇitlab自动进行备份的话，我们可以通过crontab命令来实现自动备份。强烈建议使用系统crontab命令，而不是用户crontab。 以实现每天凌晨4点进行一次自动备份为例，系统的crontab配置如下: 1vim /etc/crontab 0 4 * * * root /opt/gitlab/bin/gitlab-rake gitlab:backup:create CRON=1 然后重启crontab服务，如下： 1systemctl restart crond 1.3 保留部分备份文件随着时间的推移gitlab备份文件越来越多，服务器的磁盘空间也不够大。 此时我们就要删除部分旧的备份文件，gitlab也提供了删除旧的备份文件功能。该功能在gitlab的配置文件中，进行配置即可。 在此以保留7天之前的备份文件为例，如下： 1vim /etc/gitlab/gitlab.rb gitlab_rails[‘backup_keep_time’] = 604800 其中backup_keep_time是以秒为单位进行计算的，然后执行命令gitlab-ctl reconfigure即可。 二、gitlab仓库恢复要验证gitlab备份的有效性，我们可以把该备份文件复制到已经安装好gitlab服务器的/var/opt/gitlab/backups/目录下。然后进行数据恢复，最后访问并查看其数据完整性即可。 通过gitlab备份文件可以恢复gitlab所有的信息，包括仓库、数据库、用户、用户组、用户密钥、权限等信息。 ps：新服务器上的gitlab的版本号必须与创建备份时的gitlab版本号相同。 gitlab数据恢复比较简单，具体步骤如下： 2.1 停止相关数据连接服务在gitlab服务器上停止相关数据连接服务，命令如下： 12gitlab-ctl stop unicorngitlab-ctl stop sidekiq 2.2 恢复gitlab仓库现在我们要从1537261122_2018_09_18_9.2.5这个备份编号中，恢复数据，命令如下： 1gitlab-rake gitlab:backup:restore BACKUP=1537261122_2018_09_18_9.2.5 如果出现多个done的信息，说明整个gitlab数据就已经正常恢复完毕。 2.3 启动gitlab服务恢复完毕以后，我们现在来启动gitlab，使用以下命令： 1gitlab-ctl start 强烈建议：重启该新服务器。 三、References: gitlab的备份与恢复]]></content>
      <categories>
        <category>GitLab</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用pipenv管理python项目]]></title>
    <url>%2F2018%2F11%2F19%2Fpipenv%2F</url>
    <content type="text"><![CDATA[安装pipenv1pip install pipenv 进入你的project目录，并install12cd your_projectpipenv install pipenv install将在项目目录中创建两个新文件Pipfile和Pipfile.lock，如果项目不存在，则为项目创建一个新的虚拟环境。 如果你添加–two或–three标志到上面的最后一个命令，它分别使用Python 2或3来初始化你的项目。 否则将使用默认版本的Python。 ps:有可能会出现如下错误，应该是pyenv造成的 1234... File &quot;/usr/lib/python3.7/site-packages/pipenv/vendor/pythonfinder/models/python.py&quot;, line 70, in get_version_order version_order = [versions[v] for v in parse_pyenv_version_order()]TypeError: &apos;NoneType&apos; object is not iterable 这时可以使用下面的命令解决: 1pyenv global 3.7.1 3.7.1换成你用pyenv安装过的环境 管理Python依赖关系Pipfile包含关于项目的依赖包的信息，并取代通常在Python项目中使用的requirements.txt文件。 如果你在具有requirements.txt文件的项目中启动了Pipenv，则在把它从项目中删除之前，应该使用Pipenv安装该文件中列出的所有依赖包。 要为你的项目安装Python包，请使用install关键字。 例如， pipenv install requests将安装当前版本的requests包。 可以使用uninstall关键字以类似的方式删除包; pipenv uninstall requests将安装当前版本的requests包。 可以通过更新Pipfile.lock来冻结软件包名称及其版本以及其自己的依赖关系的列表。 这是使用lock关键字完成的; pipenv lock如果另一个用户克隆存储库，可以添加Pipfiles到你的Git存储库， 这样他们只需要在他们的系统中安装Pipenv，然后键入pipenv installPipenv会自动找到Pipfiles，创建一个新的虚拟环境，并安装必要的软件包。 管理你的开发环境通常有一些Python包只在你的开发环境中需要，而不是在你的生产环境中，例如单元测试包。 Pipenv将使用–dev标志保持两个环境分开。 例如， pipenv install --dev ipython将安装ipython，但也将其关联为只在你的开发环境中需要的软件包。 这很有用，因为现在，如果你要在你的生产环境中安装你的项目， pipenv install默认情况下不会安装ipython包。 但是，如果另一个开发人员将你的项目克隆到自己的开发环境中，他们可以使用–dev标志， pipenv install –dev安装所有依赖项，包括开发包。 激活开发环境pipenv shell 总结pipenv使得开发和管理项目包的过程变成的简单，让我们尽早使用起来吧。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django常见错误解决办法]]></title>
    <url>%2F2018%2F11%2F19%2Fdjango-errors%2F</url>
    <content type="text"><![CDATA[ProgrammingError: relation “default_cache_table” does not exist 123......django.db.utils.ProgrammingError: relation &quot;default_cache_table&quot; does not existLINE 1: SELECT cache_key, value, expires FROM &quot;default_cache_table&quot; WHERE ca... 类似上述这种错误，可以用下面这句命令解决: 1python manage.py createcachetable]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL允许被远程访问]]></title>
    <url>%2F2018%2F11%2F19%2Fpostgresql-remote%2F</url>
    <content type="text"><![CDATA[1.修改postgresql.confpostgresql.conf存放位置在/etc/postgresql/9.x/main下，这里的x取决于你安装PostgreSQL的版本号，编辑或添加下面一行，使PostgreSQL可以接受来自任意IP的连接请求。 1listen_addresses = &apos;*&apos; 2.修改pg_hba.conf修改pg_hba.conf位置与postgresql.conf相同，虽然上面配置允许任意地址连接PostgreSQL，但是这在pg中还不够，我们还需在pg_hba.conf中配置服务端允许的认证方式。任意编辑器打开该文件，编辑或添加下面一行。 12# TYPE DATABASE USER CIDR-ADDRESS METHODhost all all 0.0.0.0/0 md5 默认pg只允许本机通过密码认证登录，修改为上面内容后即可以对任意IP访问进行密码验证。对照上面的注释可以很容易搞明白每列的含义，具体的支持项可以查阅文末参考引用。 完成上两项配置后执行sudo service postgresql restart重启PostgreSQL服务后，允许外网访问的配置就算生效了。]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-celery实现定时任务]]></title>
    <url>%2F2018%2F11%2F16%2Fdjango-celery%2F</url>
    <content type="text"><![CDATA[介绍我们知道celery可以直接用在django项目中，但是配置稍微繁琐，还有添加定时任务需要重启celery beat进程，实在蛋疼，好在找到了django-celery这个模块，话不多说，让我们用起来吧。 安装和配置安装还是很简单的，直接pip即可 1pip install django-clery 此时会将一些依赖库一并安装，比如celery等 接下来是django项目中的配置，在settings中配置如下: 1234567891011121314# INSTALLED_APPS中加入djceleryINSTALLED_APPS = [ .... &apos;djcelery&apos;]# 配置djcelery相关参数，ResultStore默认存储在数据库可不必重写 ，djcelery.setup_loader()BROKER_URL = &apos;redis://127.0.0.1:6379/8&apos; # 配置你的redis地址和库# 使用和Django一样的时区CELERY_TIMEZONE = TIME_ZONE# 以上为基本配置，以下为周期性任务定义CELERYBEAT_SCHEDULER = &apos;djcelery.schedulers.DatabaseScheduler&apos; 同步数据库 1python manage.py migrate 创建task在你的app下面创建一个tasks.py文件，文件名必须一致，django-celery默认情况下会自动从各个app中寻找该模块。 12345from celery import task@task()def send_msg(msg): print(msg) 注意：task装饰器的name参数最好和函数名一致或者干脆不指定;最好不指定，这样下方分发任务时好统一处理。 创建定时任务接下来我们就可以在Django admin中创建定时任务了 启动beat和worker1python manage.py celery worker -l info 1python manage.py celery beat 之后就可以观察日志了，另外可以使用supervisor来管理这两个进程。 利用queue分发任务在settings中增加如下配置: 1234567891011121314# 定义任务对应的queueclass TasksRouter(object): @classmethod def route_for_task(cls, task, args=None, kwargs=None): task_routes = &#123; &apos;algorithm.product.tasks.*&apos;: &#123;&apos;queue&apos;: &apos;product&apos;&#125;, &apos;algorithm.material.tasks.*&apos;: &#123;&apos;queue&apos;: &apos;material&apos;&#125;, &#125; for route_key in task_routes: if re.search(route_key, task): return task_routes[route_key]CELERY_ROUTES = (TasksRouter(), ) 配置完成之后，启动beat和worker 1python manage.py celery beat beat会实时检测任务的变化，在django admin界面对任务进行操作，均会刷新该进程，使得分派任务变得非常简单。 1python manage.py celery worker -Q product 上述命令启动的worker只会监测并执行product这个queue中的任务，即只执行algorithm.product.tasks下面的任务。同理python manage.py celery worker -Q material只执行algorithm.material.tasks下面的任务。 另外queue可以添加多个,例如python manage.py celery worker -Q product,material。 若要不区分queue执行所有任务，只需python manage.py celery worker即可,但不推荐,开启任务分发之后，最好分开执行，日志方面也更好排查。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux在局域网如何通过hostname获取其ip]]></title>
    <url>%2F2018%2F11%2F16%2Flinux-hostname_to_ip%2F</url>
    <content type="text"><![CDATA[只需要hostname固定，就可以在局域网通过ping hostname.local来获取其ip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Django中实现queryset级别缓存]]></title>
    <url>%2F2018%2F11%2F16%2Fdjango-queryset-cache%2F</url>
    <content type="text"><![CDATA[介绍实现queryset级别的缓存，不是view层面的，相当于缓存sql查询结果。 使用首先在你的django项目中安装依赖的模块1pip install django-cache-machine 创建queryset_cache.py文件,文件内容如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#! /usr/bin/env python# -*- coding: utf-8 -*-# __author__ = "Breakering"# Date: 18-8-29"""依赖django-cache-machine，并在此基础上实现了轻松切换使用queryset级别缓存以及count等缓存"""import contextlibfrom caching import configfrom caching.base import CachingQuerySet, cached_withfrom django.db.models.sql import querydef queryset_cache_decorator(always_cached=True): """queryset级别缓存的装饰器，可以使得queryset直接从缓存中获取数据""" def wrapper(func): def inner(self, *args, **kwargs): queryset = func(self, *args, **kwargs) if always_cached: # 此装饰器默认从cache中获取数据 queryset = queryset.from_cache() else: with contextlib.suppress(Exception): queryset_cache_time = self.request.query_params.get('queryset_cache_time', '') if queryset_cache_time and queryset_cache_time.isdigit(): queryset = queryset.from_cache(int(queryset_cache_time)) return queryset return inner return wrapperdef queryset_cache_count_decorator(always_cached=True): """queryset count缓存的装饰器，可以使得queryset直接从缓存中获取count的值""" def wrapper(func): def inner(self, *args, **kwargs): queryset = func(self, *args, **kwargs) if always_cached: # 此装饰器默认从cache中获取数据 queryset = queryset.cache_count() else: with contextlib.suppress(Exception): queryset_cache_time = self.request.query_params.get('queryset_cache_time', '') if queryset_cache_time and queryset_cache_time.isdigit(): queryset = queryset.cache_count(int(queryset_cache_time)) return queryset return inner return wrapperclass CachedQuerySet(CachingQuerySet): """ Return queryset from cache if query_key in cache """ def __init__(self, *args, **kwargs): super(CachedQuerySet, self).__init__(*args, **kwargs) self.timeout = config.NO_CACHE # 默认直接从数据库取数据 self.cache_count_timeout = config.NO_CACHE # 自定义queryset count的缓存时间 def _clone(self, *args, **kw): qs = super(CachedQuerySet, self)._clone(*args, **kw) qs.cache_count_timeout = self.cache_count_timeout return qs def from_cache(self, timeout=60*60): """在queryset中调用此函数则是从缓存中获取,且调用之后返回的仍是queryset""" self.timeout = timeout return self._clone() def cache_count(self, cache_count_timeout=60*60): """实现queryset count的缓存,且调用之后返回的仍是queryset""" self.cache_count_timeout = cache_count_timeout return self._clone() # todo values目前的实现方式有BUG，现已取消 # def values(self, *fields, **expressions): # """rewrite queryset's values""" # if self.timeout == config.NO_CACHE: # 默认情况下values直接从数据库获取数据 # return super(CachedQuerySet, self).values(*fields, **expressions) # # clone = self._clone() # clone.query.set_values(fields) # key = make_key('values:&#123;key&#125;'.format(key=clone.query_key())) # val = cache.get(key) # if val is None: # val = super(CachedQuerySet, self).values(*fields, **expressions) # cache.set(key, val, self.timeout) # return val def count(self): """自定义queryset的count""" super_count = super(CachingQuerySet, self).count try: query_string = 'count:%s' % self.query_key() except query.EmptyResultSet: return 0 if self.cache_count_timeout: return cached_with(self, super_count, query_string, self.cache_count_timeout) elif self.timeout == config.NO_CACHE or config.TIMEOUT == config.NO_CACHE: return super_count() else: return cached_with(self, super_count, query_string, config.TIMEOUT) 改造您的model1234567891011from django.db import modelsfrom queryset_cache import CachedQuerySetfrom caching.base import CachingMixinclass ModelClassManger(models.Manager): def get_queryset(self): return CachedQuerySet(self.model) class ModelClass(CachingMixin, models.Model): objects = ModelClassManger() view层只需在get_queryset上加上装饰器即可1234@queryset_cache_count_decorator()@queryset_cache_decorator()def get_queryset(self): pass 如果添加了always_cached=False 1234@queryset_cache_count_decorator(always_cached=False)@queryset_cache_decorator(always_cached=False)def get_queryset(self): pass 则需要在query参数中加上queryset_cache_time=180,参数后面的数字即为缓存的时间。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo同步]]></title>
    <url>%2F2018%2F11%2F15%2Fhexo-sync%2F</url>
    <content type="text"><![CDATA[环境搭建安装Node.js用来生成静态页面, 到Node.js官网，下载最新版本, 根据提示一路安装即可 安装Git1sudo apt-get install git 安装Hexo当Node.js和Git都安装好后就可以正式安装Hexo了，终端执行如下命令： 1sudo npm install -g hexo 克隆hexo分支1git clone -b hexo https://github.com/Breakering/breakering.github.io.git 进入breakering.github.io.git创建博客 1hexo n &apos;博客名&apos; 发表博客 1hexo d -g 主题配置更新相关需要先清空缓存 1hexo clean 然后进行部署操作 1hexo d -g 一些问题 报错一: 若执行命令hexo deploy仍然报错：无法连接git或找不到git，则执行如下命令来安装hexo-deployer-git： 1npm install hexo-deployer-git --save 报错二: 若执行命令hexo d报以下错误: 123ERROR Plugin load failed: hexo-server //或者类似的错误 ERROR Plugin load failed: hexo-renderer-sass 则执行响应的命令: 123sudo npm install hexo-server//或者sudo npm install hexo-renderer-sass]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo初识]]></title>
    <url>%2F2018%2F09%2F28%2Fhexo-start%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网穿透frp]]></title>
    <url>%2F2018%2F09%2F28%2Ffrp%2F</url>
    <content type="text"><![CDATA[一、内网穿透原理简单地说，内网穿透依赖于 NAT 原理，根据 NAT 设备不同大致可分为以下 4 大类(前3种NAT类型可统称为cone类型)： 全克隆(Full Cone)：NAT 把所有来自相同内部 IP 地址和端口的请求映射到相同的外部 IP 地址和端口上，任何一个外部主机均可通过该映射反向发送 IP 包到该内部主机 限制性克隆(Restricted Cone)：NAT 把所有来自相同内部 IP 地址和端口的请求映射到相同的外部 IP 地址和端口；但是，只有当内部主机先给 IP 地址为 X 的外部主机发送 IP 包时，该外部主机才能向该内部主机发送 IP 包 端口限制性克隆(Port Restricted Cone)：端口限制性克隆与限制性克隆类似，只是多了端口号的限制，即只有内部主机先向 IP 地址为 X，端口号为 P 的外部主机发送1个 IP 包,该外部主机才能够把源端口号为 P 的 IP 包发送给该内部主机 对称式NAT(Symmetric NAT)：这种类型的 NAT 与上述3种类型的不同，在于当同一内部主机使用相同的端口与不同地址的外部主机进行通信时， NAT 对该内部主机的映射会有所不同；对称式 NAT 不保证所有会话中的私有地址和公开 IP 之间绑定的一致性；相反，它为每个新的会话分配一个新的端口号；导致此种 NAT 根本没法穿透 内网穿透的作用就是利用以上规则，创建一条从外部服务器到内部设备的 “隧道”，具体的 NAT 原理等可参考 内网打洞、网络地址转换NAT原理。 二、环境准备实际上根据以上 NAT 规则，基本上大部分家用设备和运营商上级路由等都在前三种规则之中，所以只需要借助成熟的内网穿透工具即可，以下为本次穿透环境 最新版本 frp 一台公网 VPS 服务器 内网一台服务器，最好 Linux 系统 三、服务端搭建服务器作为公网访问唯一的固定地址，即作为 server 端；内网客户端作为 client 端，会主动向 server 端创建连接，此时再从 server 端反向发送数据即可实现内网穿透 3.1). 下载并解压frp可以查看releases获取最新的版本,选好版本之后使用以下命令: 123wget https://github.com/fatedier/frp/releases/download/v0.21.0/frp_0.21.0_linux_amd64.tar.gztar -zxvf frp_0.21.0_linux_amd64.tar.gzcd frp_0.21.0_linux_amd64 3.2). 编辑frps.ini1234567891011121314151617181920212223242526272829303132333435[common] # frp 监听地址bind_addr = 0.0.0.0bind_port = 7000# 如果需要代理 web(http) 服务，则开启此端口vhost_http_port = 8080vhost_https_port = 4443# frp 控制面板dashboard_port = 7500dashboard_user = userdashboard_pwd = pwd# 默认日志输出位置(这里输出到标准输出)log_file = /tmp/frps.log# 日志级别，支持: debug, info, warn, errorlog_level = infolog_max_days = 3# 是否开启特权模式(特权模式下，客户端更改配置无需更新服务端)privilege_mode = true# 授权 token 建议随机生成privilege_token = cc23*********************d072734# 特权模式下允许分配的端口(避免端口滥用)privilege_allow_ports = 4000-50000# 后端连接池最大连接数量max_pool_count = 100# 口令超时时间authentication_timeout = 900# 子域名(特权模式下将 *.xxxx.com 解析到公网服务器)subdomain_host = xxxx.com 其他具体配置说明请参考frp README 文档 3.3). 启动frp server设置完成后执行 ./frps -c frps.ini 启动即可 ps:当然也可以使用supervisor来管理 四、客户端配置客户端作为发起链接的主动方，只需要正确配置服务器地址，以及要映射客户端的哪些服务端口等即可 4.1). 下载并解压frp123wget https://github.com/fatedier/frp/releases/download/v0.21.0/frp_0.21.0_linux_amd64.tar.gztar -zxvf frp_0.21.0_linux_amd64.tar.gzcd frp_0.21.0_linux_amd64 4.2). 编辑frpc.ini12345678910111213141516171819202122232425262728293031323334353637[common]server_addr = 127.0.0.1server_port = 7000# console or real logFile path like ./frpc.loglog_file = /tmp/frpc.log# debug, info, warn, errorlog_level = debuglog_max_days = 3# 特权模式，要和服务器端的配置一致privilege_token = cc23*********************d072734[gitlab]type = httplocal_port = 8080subdomain = gitlab # 这样只要访问http://gitlab.xxxx.com:8080即可访问到该客户端的gitlab服务use_gzip = true[gitlab_static_file]type = tcpremote_port = 8082plugin = static_file# 要对外暴露的文件目录plugin_local_path = /opt/gitlab/embedded/service/gitlab-rails/public/assets/# 访问 url 中会被去除的前缀，保留的内容即为要访问的文件路径plugin_strip_prefix = assets#plugin_http_user = abc#plugin_http_passwd = abc[gitlab_ssh]type = tcp local_ip = 127.0.0.1local_port = 22remote_port = 8081 其他具体配置说明请参考frp README 文档 4.3). 启动frp client设置完成后执行 ./frpc -c frpc.ini 启动即可 ps:当然也可以使用supervisor来管理 五、测试服务端和客户端同时开启完成后，即可访问 http://127.0.0.1:7500 进入 frp 控制面板，如下此时通过 ssh root@127.0.0.1 -p 8081 即可ssh到gitlab，通过访问http://gitlab.xxxx.com:8080 即可访问gitlab服务 六、GitLab通过frp代理通过上述配置，确实可以通过 http://gitlab.xxxx.com:8080 访问gitlab服务,但是你会发现缺少静态文件,因为gitlab的静态文件是nginx代理的，走的tcp协议,需要一种解决方案。 方案一、使用frp的static_file的插件虽然可以成功，通过 http://127.0.0.1:8082 即可访问gitlab的静态文件，并且也可以通过nginx反向代理到gitlab.xxxx.com这个域名上，但是速度会很慢很慢,nginx配置如下: 12345678910server &#123; listen 80; server_name gitlab.xxxx.com; location / &#123; proxy_pass http://gitlab.xxxx.com:8080; &#125; location /assets &#123; proxy_pass http://127.0.0.1:8082; &#125; &#125; 方案二、将gitlab静态文件移至服务器上，用nginx代理gitlab静态文件在如下位置/opt/gitlab/embedded/service/gitlab-rails/public/assets/放至服务器，并配置nginx如下:12345678910server &#123; listen 80; server_name gitlab.xxxx.com; location / &#123; proxy_pass http://gitlab.xxxx.com:8080; &#125; location /assets &#123; alias /webapps/gitlab/public/assets; &#125;&#125; 这样即可通过 http://gitlab.xxxx.com 正常访问内网的gitlab了 但是这样还没结束，你会发现外网通过git clone http://gitlab.xxxx.com/zhuqian/licaishi.git ,根本没法正常克隆仓库，那有啥用啊，别急，咋们还可以用ssh方式啊。 上面我们已经配置gitlab的22端口映射到服务器的8081端口了，所以可以这样克隆: 123git clone ssh://git@127.0.0.1:8081/zhuqian/licaishi.git# 或者git clone ssh://git@gitlab.xxxx.com:8081/zhuqian/licaishi.git 对于pip install的话，可以这样： 123pip install git+ssh://git@127.0.0.1:8081/zhuqian/algorithm.git# 或者pip install git+ssh://git@gitlab.xxxx.com:8081/zhuqian/algorithm.git 你以为就这样完了，还没有，我们想要直接能在gitlab项目首页直接能够显示git访问方法，效果如下: 要实现此效果，只需配置下/etc/gitlab/gitlab.rb即可： 123456...external_url &apos;http://gitlab.xxxx.com&apos;...gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 8081... 另外需要注意下nginx[&#39;listen_addresses&#39;] = [&#39;192.168.10.60&#39;]，需要对应到本地的ip地址 配置完之后: 1gitlab-ctl reconfigure 然后通过域名访问gitlab即可实现上述效果了，只不过http方式目前还无法解决。 七、由mtu引起的无法访问的问题如果frp的admin界面一切正常，但是就是无法获取数据 那么极有可能是你本地的网络最大分片小于服务器的最大分片，导致数据无法发送出去,解决办法是减小服务器的mtu: 1sudo ifconfig eth0 mtu 1000 up 其他修改mtu的方式请自行google。 八、References: 利用 frp 进行内网穿透]]></content>
      <categories>
        <category>内网穿透</category>
      </categories>
  </entry>
</search>
